$[include "Types.bard"]
$[include "Scanner.bard"]
$[include "TokenReader.bard"]

class Parser
  PROPERTIES
    reader      : TokenReader
    this_type   : Type
    this_method : Method
    local_declarations   = Local[]   # work list
    string_buffer = StringBuilder()

    pending_files     = String[]
    processed_files   = String[]

    requisite_all : Logical

    alias_args    : Cmd[]

    parsing_properties : Integer


  METHODS
    method init

    method init( filepath:String )
      local scanner = BardScanner()
      local tokens = scanner.tokenize( filepath )
      reader = TokenReader( tokens )

    method init( filepath:String, data:String )
      local scanner = BardScanner()
      local tokens = scanner.tokenize( filepath, data )
      reader = TokenReader( tokens )

    method init( this_type, this_method, tokens:Token[] )
      reader = TokenReader( tokens )

    method include( filepath:String, t=null:Token )
      contingent
        sufficient (File(filepath).exists)

        if (filepath.ends_with(".bard"))
          local base = filepath.before_first(".bard")
          local f = File( base, filepath )
          if (f.exists)
            filepath = f.filepath
            sufficient true
          endIf

          forEach (source_folder in Zorc.source_folders)
            f = File( source_folder, base ).add_path( filepath )
            if (f.exists)
              filepath = f.filepath
              sufficient true
            endIf
          endForEach

        endIf

        forEach (source_folder in Zorc.source_folders)
          if (File(source_folder,filepath).exists)
            filepath = source_folder + filepath
            sufficient true
          endIf
        endForEach

        necessary false

      satisfied
        # Recursively include all .bard files in a folder.
        if (File.is_folder(filepath))
          forEach (nested_filepath in FileList(filepath,"**/*.bard"))
            include( File(filepath,nested_filepath).filepath, t )
          endForEach
          return
        endIf

      unsatisfied
        local message = "File not found: $." (filepath)
        if (t?) throw t.error( message )
        else    throw BardError( message )

      endContingent

      filepath = File.absolute_filepath( filepath )

      Zorc.add_source_folder( File.path(filepath) )
      pending_files.add( filepath )

    method parse_pending_files
      while (pending_files.count?)
        local filepath = pending_files.remove_first
        if (processed_files.contains(filepath)) nextIteration
        processed_files.add( filepath )
        parse( filepath )
      endWhile

    method parse( filepath:String )
      init( filepath )

      requisite_all = false
      parse_content

    method peek->Token
      return reader.peek

    method peek( num_ahead:Integer )->Token
      return reader.peek( num_ahead )

    method read->Token
      return reader.read

    method read_identifier->String
      if (not next_is(Token.identifier)) throw peek.error( "Identifier expected instead of '$'." (peek) )
      return read->String

    method read_placeholder_name->String
      if (not next_is(Token.type_placeholder)) throw peek.error( "$" + "PlaceholderName expected instead of '$'." (peek) )
      return read->String

    method next_is( token_type:Integer )->Logical
      if (not reader.has_another) return false
      return (peek.type == token_type)

    method next_is_end_command->Logical
      return next_is(Token.eol) or next_is(Token.symbol_semicolon)

    method next_is_statement->Logical
      if (not reader.has_another) return false
      return peek.type > Token.last_non_statement

    method consume( token_type:Integer )->Logical
      if (not next_is(token_type)) return false
      read
      return true

    method consume( id:String )->Logical
      if (not next_is(Token.identifier)) return false
      if (peek->String != id) return false
      read
      return true

    method consume_eols->Logical
      local found = false
      while (consume(Token.eol)) found = true
      return found

    method consume_end_commands->Logical
      local found = false
      while (consume(Token.eol) or consume(Token.symbol_semicolon)) found = true
      return found

    method consume_token_and_period( type:Integer )->Logical
      if (peek(0).type == type and peek(1).type == Token.symbol_period) read; read; return true
      return false

    method must_consume( token_type:Integer )
      if (consume(token_type)) return
      #throw peek.error( "'$' expected, found '$'." (Token("",1,1,token_type),peek) )
      throw peek.error( "'" + Token.name_of(token_type) + "' expected, found '" + peek + "'." )

    method must_consume_eol
      must_consume( Token.eol )

    method parse_content
      consume_eols
      while (reader.has_another)
        if (next_is(Token.keyword_class))
          # class
          local name = parse_template( Attributes.flag_class, Token.keyword_endClass )
          if (Types.main_type_name is null) Types.main_type_name = name

        elseIf (next_is(Token.keyword_aspect))
          # aspect
          parse_template( Attributes.flag_aspect, Token.keyword_endAspect )

        elseIf (next_is(Token.keyword_compound))
          # compound
          parse_template( Attributes.flag_compound|Attributes.flag_functional, Token.keyword_endCompound )

        elseIf (next_is(Token.keyword_primitive))
          # primitive
          parse_template( Attributes.flag_primitive|Attributes.flag_functional, Token.keyword_endPrimitive )

        elseIf (next_is(Token.keyword_augment))
          parse_augment

        elseIf (next_is(Token.keyword_enumeration))
          parse_template( Attributes.flag_compound|Attributes.flag_functional, Token.keyword_endEnumeration )

        elseIf (consume(Token.symbol_open_directive))
          if (consume("include"))
            if (next_is(Token.literal_String))
              local t2 = read
              include( t2->String, t2 )
            else
              throw peek.error( //"filename" expected.// )
            endIf
          elseIf (consume("requisiteAll"))
            requisite_all = true
          else
            throw peek.error( "Expected 'include'." )
          endIf
          must_consume(Token.symbol_close_bracket)

        else
          throw peek.error( "Syntax error - unexpected '" + peek + "'." )
        endIf
        consume_eols
      endWhile

    method parse_template( flags:Integer, end_type:Integer )->String
      local t = read
      local name : String
      local placeholder_name : String
      local is_enumeration = (end_type == Token.keyword_endEnumeration)

      if (next_is(Token.type_placeholder) and not is_enumeration)
        name = "[]"
        placeholder_name = read->String
        must_consume( Token.symbol_empty_brackets )
      else
        name = read_identifier
      endIf

      local templ = Template( t, name, flags )
      if (placeholder_name?)
        templ.placeholder_names.add( placeholder_name )
        templ.generic_type_names.add( "Object" )
        templ.is_generic = true

      elseIf (consume(Token.symbol_open_specialize))
        if (is_enumeration) throw peek.error( "Enumerations cannot be templates or generic classes." )

        # Parse <<$Placeholder,$Names>>
        if (next_is(Token.identifier))
          # Template override with specific types
          local first = true
          name += "<<"
          while (first or consume(Token.symbol_comma))
            if (first) first = false
            else       name += ","

            if (next_is(Token.type_placeholder)) 
              throw peek.error( "Either all specializers must be $PlaceholderTypes or none of them can be." )
            endIf
            name += parse_type.name
          endWhile
          name += ">>"
        else
          # Template with placeholder types
          local first = true
          while (first or consume(Token.symbol_comma))
            first = false
            templ.placeholder_names.add( read_placeholder_name )

            if (consume(Token.symbol_colon))
              templ.is_generic = true
              while (templ.generic_type_names.count + 1 < templ.placeholder_names.count) templ.generic_type_names.add(null as String)
              templ.generic_type_names.add( parse_type.name )

            elseIf (templ.is_generic)
              templ.generic_type_names.add( null as String )

            endIf

          endWhile
        endIf
        must_consume( Token.symbol_close_specialize )
      endIf
      local tokens = templ.tokens

      if (Templates.contains(name)) throw t.error( //A type named "// + name + //" already exists.// )

      if (is_enumeration)
        local enumeration_names   = String[]
        local enumeration_indices = Integer[]
        local next_enumeration_index = 0

        if (consume(Token.symbol_open_paren))
          local first = true
          while (first or consume(Token.symbol_comma) or consume(Token.eol))
            if (not first and next_is(Token.symbol_close_paren)) escapeWhile

            first = false

            consume_eols

            local e_t = peek
            local e_name = read_identifier
            if (enumeration_names.contains(e_name)) throw e_t.error( "Duplicate enumeration category '$'." (e_name) )
            enumeration_names.add( e_name )
            enumeration_indices.add( next_enumeration_index )
            ++next_enumeration_index
          endWhile

          consume_eols
          must_consume( Token.symbol_close_paren )

        else
          if (not consume(Token.eol)) throw t.error( "(category1,category2,...) or EOL expected." )

          consume_eols
          must_consume( Token.keyword_CATEGORIES )
          consume_eols
          while (next_is(Token.identifier))
            local first = true
            while (first or consume(Token.symbol_comma))
              first = false

              local e_t = peek
              local e_name = read_identifier
              if (enumeration_names.contains(e_name)) throw e_t.error( "Duplicate enumeration category '$'." (e_name) )
              enumeration_names.add( e_name )
              enumeration_indices.add( next_enumeration_index )
              ++next_enumeration_index
            endWhile

            consume_eols
          endWhile

        endIf


        local enum_body = StringBuilder()
        enum_body.println "( index:Integer )"
        enum_body.println "  SETTINGS"
        forEach (i of enumeration_names)
          enum_body.println "    $ = $()($)" (enumeration_names[i],name,enumeration_indices[i])
        endForEach
        enum_body.print "    categories = ["
        local first = true
        forEach (e_name in enumeration_names)
          if (first) first = false
          else       enum_body.print ","
          enum_body.print( //"$"// (e_name) )
        endForEach
        enum_body.println "]"
        enum_body.println
        enum_body.println "  METHODS"
        enum_body.println "    method equals( other:$ )->Logical" (name)
        enum_body.println "      return index == other.index"
        enum_body.println
        enum_body.println "    method to->String"
        enum_body.println "      return categories[index]"

        #trace enum_body
        tokens.add( BardScanner().tokenize( "enumeration $"(name), enum_body->String ) )
        t = read
        tokens.add( t )

      else
        # Parse out [attribute tags] before the next EOL or ';', storing other tokens in template
        while (t.type != Token.eol)
          if (not reader.has_another) throw t.error( "'$' expected before End of File." (Token.name_of(end_type)) )

          t = peek
          if (t.type == Token.symbol_open_bracket)
            parse_attributes( templ.attributes )
            escapeWhile
          elseIf (t.type == Token.symbol_semicolon)
            reader.read

            t = Token(t)
            t.type = Token.eol
            tokens.add( t )

            t = Token(t)
            t.type = end_type
            tokens.add( t )

            escapeWhile
          else
            tokens.add( reader.read )
          endIf
        endWhile
      endIf

      # Blindly store all remaining tokens up to and including endClass/endAspect etc.
      while (t.type != end_type)
        if (not reader.has_another) throw t.error( "'$' expected before End of File." (Token.name_of(end_type)) )

        t = read
        tokens.add( t )
      endWhile

      Templates[name] = templ
      return name

    method parse_augment
      local t = read
      local name : String
      local placeholder_name : String
      if (next_is(Token.type_placeholder))
        name = "[]"
        placeholder_name = read->String
        must_consume( Token.symbol_empty_brackets )
      else
        name  = read_identifier
        name += parse_specialization_string
        if (consume(Token.symbol_empty_brackets))
          name += "[]"
          if (next_is(Token.symbol_empty_brackets))
            throw peek.error( "Cannot augment multidimensional lists because they map to generic list Object[]." )
          endIf
        endIf
      endIf

      local tokens = Token[]
      local aug = Augment( t, name, tokens )

      # Additional base types
      if (consume(Token.symbol_colon))
        local first = true
        while (first or consume(Token.symbol_comma))
          first = false
          aug.base_types.add( parse_type )
        endWhile
      endIf

      if (not consume(Token.symbol_semicolon))
        local t2 = read
        while (t2.type != Token.keyword_endAugment)
          tokens.add( t2 )

          t2 = read
          if (not reader.has_another) throw t2.error( "'endAugment' expected before End of File." )
        endWhile
      endIf

      local list = Types.augments[name]
      if (list is null)
        list = Augment[]
        Types.augments[name] = list
      endIf
      list.add( aug )


    method parse_type_def( this_type, tokens:Token[] )
      reader = TokenReader( tokens )
      local end_type = tokens.last.type

      if (consume(Token.symbol_open_paren))
        local ids = Token[]
        local direct_flags = Logical[]
        local first = true
        while (first or consume(Token.symbol_comma))
          first = false

          consume_eols

          direct_flags.add( consume(Token.symbol_at) )
          ids.add( read )

          if (consume(Token.symbol_colon))
            local property = Property( ids.last, this_type, ids.last->String )
            property.type = parse_type
            this_type.add_property( property )
          endIf

        endWhile
        consume_eols
        must_consume( Token.symbol_close_paren )

        # Generate an init() or create() method based on the auto-configure parameters.
        local m : Method
        if (this_type.is_compound) m = Method( this_type.t, this_type, "create" )
        else                       m = Method( this_type.t, this_type, "init" )
        m.return_type = this_type
        m.attributes.add( Attributes.flag_automatic )
        forEach (index of ids)
          local id = ids[index]
          local param = Local( id, id->String, null )
          param.is_direct = direct_flags[index]
          m.add_parameter( param )
        endForEach
        this_type.add_method( m )
      endIf

      if (consume(Token.symbol_colon))
        local first = true
        while (first or consume(Token.symbol_comma))
          first = false
          this_type.base_types.add( parse_type )
        endWhile
      endIf

      #parse_attributes( this_type.attributes )
      must_consume_eol
      consume_eols
      local cur_category = Token.keyword_METHODS
      local next_enumeration_value = 0
      while (reader.has_another and not next_is(end_type))
        if (consume(Token.keyword_SETTINGS))
          cur_category = Token.keyword_SETTINGS
          must_consume_eol

        elseIf (consume(Token.keyword_ENUMERATE))
          cur_category = Token.keyword_ENUMERATE
          must_consume_eol

        elseIf (consume(Token.keyword_PROPERTIES))
          cur_category = Token.keyword_PROPERTIES
          must_consume_eol

        elseIf (consume(Token.keyword_METHODS))
          cur_category = Token.keyword_METHODS
          must_consume_eol

        elseIf (consume(Token.keyword_EXTERNAL))
          if (consume(Token.keyword_METHODS))
            cur_category = Token.keyword_METHODS
          elseIf (consume(Token.keyword_PROPERTIES))
            cur_category = Token.keyword_PROPERTIES
          else
            throw peek.error( "'PROPERTIES' or 'METHODS' expected." )
          endIf
          must_consume_eol

        elseIf (consume(Token.keyword_INTERNAL))
          if (consume(Token.keyword_METHODS))
            cur_category = Token.keyword_METHODS
          elseIf (consume(Token.keyword_PROPERTIES))
            cur_category = Token.keyword_PROPERTIES
          else
            throw peek.error( "'PROPERTIES' or 'METHODS' expected." )
          endIf
          must_consume_eol

        elseIf (cur_category == Token.keyword_SETTINGS)
          local found_any = false
          while (next_is(Token.identifier))
            found_any = true
            parse_property( this_type.settings_list )
          endWhile

          if (not found_any) throw peek.error( "Property name expected." )

        elseIf (cur_category == Token.keyword_ENUMERATE)
          local found_any = false
          while (next_is(Token.identifier))
            found_any = true
            next_enumeration_value = parse_enumerated_setting( this_type.settings_list, next_enumeration_value )
            consume( Token.symbol_comma )
          endWhile

          if (not found_any) throw peek.error( "Enumerated value expected." )

        elseIf (cur_category == Token.keyword_PROPERTIES)
          if (this_type.is_native or not this_type.is_reference)
            throw peek.error( "This type does not support additional properties." )
          endIf

          local found_any = false
          while (next_is(Token.identifier))
            found_any = true
            parse_property( this_type.property_list )
          endWhile

          if (not found_any) throw peek.error( "Property name expected." )

        elseIf (cur_category == Token.keyword_METHODS)
          local found_any = false
          while (next_is(Token.keyword_method) or next_is(Token.keyword_task) or next_is(Token.keyword_alias))
            found_any = true

            if (next_is(Token.keyword_alias))
              parse_alias
            else
              parse_method
            endIf
          endWhile

          if (not found_any) throw peek.error( "Keyword 'method' or '$' expected, found '$'." (tokens.last,peek) )
        endIf

        consume_eols

      endWhile

      must_consume( end_type )

    method parse_attributes( attributes:Attributes )
      if (consume(Token.symbol_open_bracket))
        while (reader.has_another and not next_is(Token.symbol_close_bracket))
          local at_sign = consume( Token.symbol_at )
          local id = read_identifier
          if (at_sign) id = "@" + id
          attributes.add( id )
          consume( Token.symbol_comma )
        endWhile
        must_consume( Token.symbol_close_bracket )
      endIf

      if (requisite_all) attributes.add( "requisiteAll" )

    method parse_type->Type
      return parse_type( true )

    method parse_delegate_or_task_type_name( t:Token, name:String )->String
      if (name == "Delegate")
        local param_types = Type[]
        local return_type : Type

        if (consume( Token.symbol_open_paren ))
          if (not consume( Token.symbol_close_paren ))
            param_types.add( parse_type )
            while (consume( Token.symbol_comma ))
              param_types.add( parse_type )
            endWhile
            must_consume( Token.symbol_close_paren )
          endIf
        endIf
        if (consume( Token.symbol_arrow )) return_type = parse_type

        if (this_type is null or not this_type.is_generic_map)
          name = Analyzer.get_delegate_class_names(null,null,param_types,return_type)[0]
          if (Templates.find( name ) is null)
            Analyzer.create_base_delegate_type( t, name, param_types, return_type )
          endIf
        else
          name = "Object"
        endIf

      elseIf (name == "Task")
        local param_types = Type[]
        local return_type : Type

        if (consume( Token.symbol_open_paren ))
          if (not consume( Token.symbol_close_paren ))
            param_types.add( parse_type )
            while (consume( Token.symbol_comma ))
              param_types.add( parse_type )
            endWhile
            must_consume( Token.symbol_close_paren )
          endIf
        endIf
        if (consume( Token.symbol_arrow )) return_type = parse_type

        if (param_types.count? or return_type?)
          if (not this_type.is_generic_map)
            name = Analyzer.get_task_type_name( t, param_types, return_type )
          else
            name = "Object"
          endIf
        endIf
      endIf

      return name

    method parse_type( mark_new_types_as_used:Logical )->Type
      local t = peek
      local name = parse_possible_type
      return Types.reference( t, name, mark_new_types_as_used )

    method parse_possible_type->String
      local t = peek
      local name = read_identifier

      name = parse_delegate_or_task_type_name( t, name )

      if (next_is(Token.symbol_open_specialize)) name += parse_specialization_string

      while (consume(Token.symbol_empty_brackets)) name += "[]"
      return name

    method parse_enumerated_setting( list:Property[], next_value:Integer )->Integer
      local t    = peek
      local name = read_identifier
      local property = Property( t, this_type, name )

      if (consume(Token.symbol_equals))
        if (next_is(Token.literal_Integer))
          property.initial_value = parse_expression
          next_value = (property.initial_value as CmdLiteralInteger).value
        else
          throw peek.error( "Literal integer expected." )
        endIf
      else
        property.initial_value = CmdLiteralInteger( t, next_value )
      endIf

      property.is_constant = true
      property.constant_value = (property.initial_value as CmdLiteralInteger).value

      property.type = Types.type_Integer
      list.add( property )

      return next_value + 1

    method parse_property( list:Property[] )
      local first_new_property_index = list.count

      local first = true
      while (first or consume(Token.symbol_comma))
        first = false

        local t    = peek
        local name = read_identifier
        local property = Property( t, this_type, name )

        if (consume(Token.symbol_equals))
          property.initial_value = parse_expression
        endIf

        list.add( property )
      endWhile

      if (consume(Token.symbol_colon))
        local type = parse_type

        parse_attributes( list[first_new_property_index].attributes )
        local flags = list[first_new_property_index].attributes.flags

        #trace
        forEach (i in first_new_property_index..<list.count)
          #println "1 Adding attributes to " + list[i].name + " " + flags
          list[i].type = type
          list[i].attributes.add( flags )
        endForEach
      else
        parse_attributes( list[first_new_property_index].attributes )
        local flags = list[first_new_property_index].attributes.flags

        forEach (i in first_new_property_index..<list.count)
          local property = list[i]
          property.attributes.add( flags )
          if (property.type is null)
            if (property.initial_value?)
              property.type = property.initial_value.implicit_type
              if (property.type is null) throw property.t.error( "Unable to implicitly determine property type from initial value." )
            else
              throw peek.error( //" = {initial value}" and/or " : TypeName" expected.// )
            endIf
          endIf
        endForEach
      endIf

    method parse_alias
      local t = read  # 'alias'

      local a = Alias( t, read_identifier )

      if (consume(Token.symbol_open_paren))
        if (not consume(Token.symbol_close_paren))
          a.arg_names.add( read_identifier )
          while (consume(Token.symbol_comma))
            a.arg_names.add( read_identifier )
          endWhile
          must_consume(Token.symbol_close_paren)
        endIf
      endIf

      must_consume( Token.symbol_fat_arrow )

      while (reader.has_another)
        local t = reader.read
        if (t.type == Token.eol) escapeWhile

        local index = -1
        if (t.type == Token.identifier)
          index = a.arg_names.locate( t->String )
          if (index >= 0) ++index   # 0..n-1 -> 1..n 
        elseIf (t.type == Token.keyword_this)
          index = 0
        endIf

        if (index >= 0) a.tokens.add( AliasArgIndexToken(t,index) )
        else            a.tokens.add( t )
      endWhile

      consume_eols

      if (this_type.aliases is null)
        this_type.aliases = Alias[]
      endIf

      this_type.aliases.add( a )

    method parse_method( this_type )->Method
      return parse_method( this_type, false )

    method parse_method( this_type, anonymous_parameters:Logical )->Method
      return parse_method( anonymous_parameters )

    method parse_method->Method
      return parse_method( false )

    method parse_method( anonymous_parameters:Logical )->Method
      local t = read  # 'method'
      local name = parse_possible_type

      local original_context = this_type

      local disjoint_context : Type
      if (consume(Token.symbol_scope))
        disjoint_context = Types.reference( t, name, false )
        this_type = disjoint_context
        name = read_identifier
      endIf

      if (name == "operator")
        local t_type = peek.type
        if (t_type >= Token.first_definable_operator and t_type <= Token.last_definable_operator)
          name += read->String
        endIf
      endIf

      this_method = Method( t, this_type, name )
      if (t.type == Token.keyword_task) this_method.attributes.add( Attributes.flag_task )

      if (consume(Token.symbol_open_paren))
        consume_eols
        if (next_is(Token.identifier) or (not anonymous_parameters and next_is(Token.symbol_at)))
          local first = true
          local parameter_index = 1
          while (first or consume(Token.symbol_comma))
            first = false
            consume_eols
            local param_t = peek
            local param_name : String
            local param_type : Type
            local default_value : Cmd
            local is_direct = false
            if (anonymous_parameters)
              param_name = "parameter_" + parameter_index
              param_type = parse_type
            else
              if (consume(Token.symbol_at))
                is_direct = true
                param_name = read_identifier
              else
                param_name = read_identifier
                #if (param_name == name) throw param_t.error( "Auto-initializing parameter in setter method creates infinite recursion; write \"@$\" instead." (param_name) )
                if (param_name == name) throw param_t.error( "Auto-initializing parameter in setter method creates infinite recursion; write \"@" + param_name + "\" instead." )

                if (consume(Token.symbol_equals))
                  default_value = parse_expression
                endIf

                if (consume(Token.symbol_colon)) param_type = parse_type(false)
                elseIf (next_is(Token.identifier)) throw peek.error( //Parameters must be declared "name:Type" instead of "Type name".// )
              endIf
            endIf
            local param = Local( param_t, param_name, param_type )
            param.initial_value = default_value
            param.is_direct = is_direct
            this_method.add_parameter( param )
            ++parameter_index
          endWhile
        endIf
        must_consume( Token.symbol_close_paren )
      endIf

      local return_type : Type
      if (next_is(Token.symbol_period))
        throw peek.error( "Use '->' instead of '.' to declare return type." )
      endIf

      if (consume(Token.symbol_arrow))
        if (consume(Token.keyword_this))
          this_method.return_type = this_type
          this_method.attributes.add( Attributes.flag_auto_return_this )
        else
          this_method.return_type = parse_type(false)
          if (name == "to")
            name = "to_" + this_method.return_type
            this_method.name = name
          endIf
        endIf
      endIf

      if (this_method.is_task)
        if (this_method.is_initializer) throw t.error( "Initializers cannot be declared as tasks." )
        forEach (parameter in this_method.parameters)
          if (parameter.type is null)
            # We need the task type which relies on the parameter types and the parameter
            # types are not necessarily available with auto-initializing parameters.
            throw parameter.t.error( "Tasks cannot have auto-initializing parameters." )
          endIf
        endForEach

        local result_type = this_method.return_type
        this_method.yield_type = result_type
        this_method.return_type = Types.reference( t, Analyzer.get_task_type_name(t,this_method.parameters,result_type) )
      endIf

      if (name == "create")
        if (this_method.return_type?)
          if (this_method.return_type.name != this_type.name)
            throw t.error( "$::create() must return type '$'." (this_type.name,this_type.name) )
          endIf
        else
          this_method.return_type = this_type
        endIf
      endIf

      parse_attributes( this_method.attributes )

      consume( Token.symbol_colon )
      consume_eols

      this_type.add_method( this_method )

      Analyzer.push_context
      parse_multi_line_statements( this_method.body )
      Analyzer.pop_context

      this_type = original_context

      return this_method

    method parse_delegate->CmdDelegate
      local t = read
      local name = "lambda" + Analyzer.unique_id
      local lambda_method = Method( t, this_type, name )

      if (consume( Token.symbol_open_paren ))
        if (next_is( Token.identifier ))
          local first = true
          local parameter_index = 1
          while (first or consume(Token.symbol_comma))
            first = false
            local param_t = peek
            local param_name : String
            local param_type : Type
            local is_direct = false

            param_name = read_identifier
            if (param_name == name)
              #throw param_t.error( "Auto-initializing parameter in setter method creates infinite recursion; write \"@$\" instead." (param_name) )
              throw param_t.error( "Auto-initializing parameter in setter method creates infinite recursion; write \"@" + param_name + "\" instead." )
            endIf

            if (consume(Token.symbol_colon))
              param_type = parse_type
            elseIf (next_is(Token.identifier))
              throw peek.error( //Parameters must be declared "name:Type" instead of "Type name".// )
            else
              throw peek.error( //":TypeName" expected after parameter.// )
            endIf

            local param = Local( param_t, param_name, param_type )

            param.is_direct = is_direct
            lambda_method.add_parameter( param )
            ++parameter_index
          endWhile
        endIf
        must_consume( Token.symbol_close_paren )
      endIf

      if (consume(Token.symbol_arrow))
        lambda_method.return_type = parse_type
      endIf


      this_type.add_method( lambda_method )

      local temp_method = this_method
      this_method = lambda_method

      local is_multi_line = false
      Analyzer.push_context
      if (next_is(Token.eol))
        is_multi_line = true
        consume_eols
        parse_multi_line_statements( lambda_method.body )
      else
        local has_open_brace = consume( Token.symbol_open_brace )
        parse_single_line_statements( lambda_method.body )
        if (has_open_brace) must_consume( Token.symbol_close_brace )
      endIf
      Analyzer.pop_context

      this_method = temp_method

      if (is_multi_line) must_consume( Token.keyword_endDelegate )

      local parameter_types = Type[]
      forEach (param in lambda_method.parameters) parameter_types.add( param.type )

      local delegate_signature = Analyzer.get_delegate_signature( name, parameter_types, lambda_method.return_type )
      local delegate_class_names = Analyzer.get_delegate_class_names( name, this_type, parameter_types, lambda_method.return_type )

      #println(delegate_class_names)

      local cmd_delegate = CmdDelegate( t, CmdThis(t, this_type), name, ...
                                            delegate_signature, ...
                                            delegate_class_names[0], ...
                                            delegate_class_names[1], ...
                                            parameter_types, ...
                                            lambda_method.return_type )

      return cmd_delegate

    method parse_multi_line_statements( statements:CmdStatementList )
      consume_end_commands
      while (next_is_statement)
        parse_statement( statements, true )
        while (consume(Token.eol) or consume(Token.symbol_semicolon)) noAction
        consume_end_commands
      endWhile

    method parse_single_line_statements( statements:CmdStatementList )
      while (next_is_statement)
        parse_statement( statements, false )
        if (not consume(Token.symbol_semicolon)) return
        while (consume(Token.symbol_semicolon)) noAction
      endWhile

      if (not consume(Token.eol))
        if (peek.type >= Token.last_non_statement) must_consume( Token.eol )  # force an error
      endIf

    method parse_statement( statements:CmdStatementList, allow_control_structures:Logical )
      local t = peek

      if (next_is(Token.keyword_delegate))
        throw t.error( "Unused delegate definition." )
      endIf

      if (allow_control_structures)
        if (next_is(Token.keyword_if))
          statements.add( parse_if )
          return

        elseIf (next_is(Token.keyword_which))
          statements.add( parse_which )
          return

        elseIf (next_is(Token.keyword_whichIs))
          statements.add( parse_which( true ) )
          return

        elseIf (next_is(Token.keyword_forEach))
          statements.add( parse_forEach )
          return

        elseIf (next_is(Token.keyword_contingent))
          statements.add( parse_contingent )
          return

        elseIf (next_is(Token.keyword_while))
          statements.add( parse_while )
          return

        elseIf (next_is(Token.keyword_loop))
          statements.add( parse_loop )
          return

        elseIf (next_is(Token.keyword_try))
          statements.add( parse_try )
          return

        endIf
      else
        local err = false
        if (next_is(Token.keyword_if)) err = true
        if (err) throw t.error( "Control structures must begin on a separate line." )
      endIf

      if (next_is(Token.keyword_local))
        parse_local_declaration( statements )
        return

      elseIf (consume(Token.keyword_return))

        if (next_is_end_command)
          statements.add( CmdReturnNil(t) )
        else
          statements.add( CmdReturnValue(t,parse_expression) )
        endIf
        return

      elseIf (consume(Token.keyword_yield))

        if (next_is_end_command)
          statements.add( CmdYieldNil(t) )
        elseIf (this_method.is_task and this_method.return_type is null)
          throw t.error( "This task does not declare a return type." )
        else
          statements.add( CmdYieldValue(t,parse_expression) )
        endIf
        return

      elseIf (consume(Token.keyword_yieldAndWait))
        statements.add( CmdYieldAndWait(t,parse_expression) )
        return

      elseIf (consume(Token.keyword_yieldWhile))
        local cmd_while = CmdWhile( t, parse_expression )

        if (consume(Token.keyword_withTimeout))
          local t2 = peek
          local timeout_expr = parse_expression
          local timeout_name = "_timeout_" + Analyzer.unique_id
          cmd_while.condition = CmdLogicalAnd( t2,
            CmdCompareLT( t2, CmdAccess(t2, "Time", "current"), CmdAccess(t2,timeout_name) ),
            cmd_while.condition )

          local v = Local( t2, timeout_name )
          this_method.add_local( v )
          statements.add( CmdLocalDeclaration( t2, v ) )
          statements.add( 
            CmdWriteLocal( t2, v, 
              CmdAdd( t2,
                CmdAccess(t2,"Time","current"),
                timeout_expr
              )
            )
          )
        endIf

        cmd_while.body.add( CmdYieldNil(t) )
        statements.add( cmd_while )

        return

      elseIf (consume(Token.keyword_throw))
        statements.add( CmdThrow(t,parse_expression) )
        return

      elseIf (consume(Token.keyword_noAction))
        noAction
        return

      elseIf (consume(Token.keyword_trace))
        local cmd_trace = CmdTrace(t,this_method)
        while (reader.has_another)
          if (next_is(Token.symbol_semicolon) or next_is(Token.eol) or next_is(Token.symbol_close_brace))
            escapeWhile
          endIf

          local pos1 = reader.position
          t = peek
          if (consume(Token.symbol_comma))
            cmd_trace.labels.add(", ")
            cmd_trace.expressions.add( CmdLiteralString(t,", ") )
          else
            cmd_trace.expressions.add( parse_expression )
            cmd_trace.labels.add( reader.source_string(pos1,reader.position-1) )
          endIf

        endWhile
        statements.add( cmd_trace )
        return

      elseIf (consume(Token.keyword_tron))
        statements.add( CmdTron(t) )
        return

      elseIf (consume(Token.keyword_troff))
        statements.add( CmdTroff(t) )
        return
      endIf

      #{
      if (consume("println"))
        if (next_is_end_command) statements.add( CmdPrintln(t) )
        else                     statements.add( CmdPrintln(t, parse_expression) )
        return
      endIf

      if (consume("print"))
        statements.add( CmdPrintln(t, parse_expression).without_newline )
        return
      endIf
      }#

      if (consume(Token.keyword_escapeContingent))
        statements.add( CmdEscapeContingent(t) )
        return
      endIf

      if (consume(Token.keyword_escapeForEach))
        statements.add( CmdEscapeForEach(t) )
        return
      endIf

      if (consume(Token.keyword_escapeIf))
        statements.add( CmdEscapeIf(t) )
        return
      endIf

      if (consume(Token.keyword_escapeLoop))
        statements.add( CmdEscapeLoop(t) )
        return
      endIf

      if (consume(Token.keyword_escapeTry))
        statements.add( CmdEscapeTry(t) )
        return
      endIf

      if (consume(Token.keyword_escapeWhich))
        statements.add( CmdEscapeWhich(t) )
        return
      endIf

      if (consume(Token.keyword_escapeWhile))
        statements.add( CmdEscapeWhile(t) )
        return
      endIf

      if (consume(Token.keyword_nextIteration))
        statements.add( CmdNextIteration(t) )
        return
      endIf

      if (consume(Token.keyword_necessary))
        statements.add( CmdNecessary(t, parse_expression))
        return
      endIf

      if (consume(Token.keyword_sufficient))
        statements.add( CmdSufficient(t, parse_expression))
        return
      endIf

      if (consume(Token.symbol_increment))
        statements.add( CmdIncrement(t, parse_expression) )
        return
      endIf

      if (consume(Token.symbol_decrement))
        statements.add( CmdDecrement(t, parse_expression) )
        return
      endIf

      local expression = parse_expression

      t = peek
      if (consume(Token.symbol_equals))
        statements.add( CmdAssign(t,expression,parse_expression) )
        return
      endIf

      #{
      if (consume(Token.symbol_access_assign))
        local rhs = parse_expression
        local access = rhs as CmdAccess
        if (access is null) throw rhs.error( "Property access or method call expected." )
        while (access.operand?)
          local operand = access.operand as CmdAccess
          if (operand is null) throw access.operand.t.error( "Property access or method call expected." )
          access = operand
        endWhile
        access.operand = expression.clone
        statements.add( CmdAssign(t,expression,access) )
      endIf
      }#

      if (consume(Token.symbol_increment))
        statements.add( CmdIncrement(t, expression) )
        return
      endIf

      if (consume(Token.symbol_decrement))
        statements.add( CmdDecrement(t, expression) )
        return
      endIf

      local t_type = t.type
      if (t_type >= Token.first_shorthand_operator and t_type <= Token.last_shorthand_operator)
        read
        local lhs = expression.clone
        local rhs = parse_expression
        local new_value : Cmd

        which (t_type)
          case Token.symbol_add_assign:          new_value = CmdAdd( t, lhs, rhs )
          case Token.symbol_subtract_assign:     new_value = CmdSubtract( t, lhs, rhs )
          case Token.symbol_multiply_assign:     new_value = CmdMultiply( t, lhs, rhs )
          case Token.symbol_divide_assign:       new_value = CmdDivide( t, lhs, rhs )
          case Token.symbol_mod_assign:          new_value = CmdMod( t, lhs, rhs )
          case Token.symbol_power_assign:        new_value = CmdPower( t, lhs, rhs )
          case Token.symbol_bitwise_and_assign:  new_value = CmdBitwiseAnd( t, lhs, rhs )
          case Token.symbol_bitwise_or_assign:   new_value = CmdBitwiseOr( t, lhs, rhs )
          case Token.symbol_bitwise_xor_assign:  new_value = CmdBitwiseXor( t, lhs, rhs )
          case Token.symbol_access_assign
            local access = rhs as CmdAccess
            if (access is null or access.operand?) throw t.error( "Syntax error." )
            access.operand = lhs
            new_value = access
        endWhich
        statements.add( CmdAssign(t, expression, new_value) )
        return
      endIf

      # No-parens args can follow an initial expression
      if (not next_is_end_command)
        local access = expression as CmdAccess
        if (access? and access.args is null)
          local args = CmdArgs()
          while (not next_is_end_command and peek.type >= Token.last_non_statement)
            args.add( parse_expression )
          endWhile
          access.args = args
        endIf
      endIf

      statements.add( expression )

    method parse_if->CmdIf
      local t = read
      local cmd_if = CmdIf( t, parse_expression )

      if (consume_eols)
        # multi-line if
        parse_multi_line_statements( cmd_if.body )

        while (next_is(Token.keyword_elseIf))
          # Need logic to avoid dangling elseIf problems.
          local starting_position = reader.position
          t = read
          local elseIf_condition = parse_expression
          if (consume(Token.eol))
            local elseIf_body = CmdStatementList()
            parse_multi_line_statements( elseIf_body )

            cmd_if.elseIf_conditions.add( elseIf_condition )
            cmd_if.elseIf_bodies.add( elseIf_body )
          else
            reader.position = starting_position
            escapeWhile
          endIf
        endWhile

        if (next_is(Token.keyword_else) and peek(1).type == Token.eol)
          read
          cmd_if.else_body = CmdStatementList()
          parse_multi_line_statements( cmd_if.else_body )
        endIf

        must_consume( Token.keyword_endIf )

      else
        # single-line if
        parse_single_line_statements( cmd_if.body )
        consume_eols

        while (next_is(Token.keyword_elseIf))
          # Need logic to avoid dangling elseIf problems.
          local starting_position = reader.position
          t = read
          local elseIf_condition = parse_expression
          if (next_is(Token.eol))
            reader.position = starting_position
            escapeWhile
          else
            local elseIf_body = CmdStatementList()
            parse_single_line_statements( elseIf_body )
            must_consume_eol

            cmd_if.elseIf_conditions.add( elseIf_condition )
            cmd_if.elseIf_bodies.add( elseIf_body )
          endIf
        endWhile

        if (next_is(Token.keyword_else) and peek(1).type != Token.eol)
          read
          cmd_if.else_body = CmdStatementList()
          parse_single_line_statements( cmd_if.else_body )
        endIf
      endIf

      return cmd_if

    method parse_which->CmdWhich
      return parse_which( false )

    method parse_which( which_is:Logical )->CmdWhich
      local t = read

      must_consume( Token.symbol_open_paren )
      local cmd_which = CmdWhich( t, parse_expression, which_is )
      must_consume( Token.symbol_close_paren )
      must_consume_eol

      consume_eols
      local prev_case_expr : Cmd
      while (consume(Token.keyword_case))
        local which_case = CmdWhichCase( t )
        cmd_which.cases.add( which_case )
        consume_eols

        prev_case_expr = parse_expression
        while (consume( Token.symbol_comma ))
          which_case.values.add( prev_case_expr )
          prev_case_expr = parse_expression
        endWhile
        which_case.values.add( prev_case_expr )

        if (not consume( Token.eol )) must_consume( Token.symbol_colon )
        parse_multi_line_statements( which_case.body )
      endWhile

      if (consume( Token.keyword_others ))
        cmd_which.others_case = CmdStatementList()
        if (not consume( Token.eol )) must_consume( Token.symbol_colon )
        parse_multi_line_statements( cmd_which.others_case )
        # prev_case_expr = which_cmd.case_others
      endIf

      if (not which_is) must_consume( Token.keyword_endWhich )
      else              must_consume( Token.keyword_endWhichIs )

      return cmd_which

    method parse_contingent->CmdContingent
      local t = read
      local cmd_contingent = CmdContingent( t )

      parse_multi_line_statements( cmd_contingent.body )
      consume_eols

      if (consume( Token.keyword_satisfied ))
        cmd_contingent.satisfied_body = CmdStatementList()
        parse_multi_line_statements( cmd_contingent.satisfied_body )
      endIf

      if (consume( Token.keyword_unsatisfied ))
        cmd_contingent.unsatisfied_body = CmdStatementList()
        parse_multi_line_statements( cmd_contingent.unsatisfied_body )
      endIf

      must_consume( Token.keyword_endContingent )
      consume_eols

      return cmd_contingent

    method parse_while->CmdWhile
      local t = read
      local cmd_while = CmdWhile( t, parse_expression )

      if (consume_eols)
        # multi-line while
        parse_multi_line_statements( cmd_while.body )
        must_consume( Token.keyword_endWhile )
      else
        # single-line while
        parse_single_line_statements( cmd_while.body )
        consume_eols
      endIf

      return cmd_while

    method parse_forEach->Cmd
      local t = read   # 'forEach'

      local has_parens = consume( Token.symbol_open_paren )

      local control_expression = parse_expression
      local cmd_forEach : CmdIterationControlStructure

      if ((has_parens and consume(Token.symbol_close_paren)) or (not has_parens and next_is(Token.eol)))
        # Anonymous forEach:
        #   forEach (control_expression)
        if (control_expression instanceOf CmdRange)
          local range = control_expression as CmdRange : CmdRange
          if (range?)
            if (range instanceOf CmdRangeUpTo)
              cmd_forEach = CmdForEachValueInRangeUpTo( t, t, null, range.t, range.first_expression, range.last_expression, true )
            elseIf (range instanceOf CmdRangeUpToLessThan)
              cmd_forEach = CmdForEachValueInRangeUpTo( t, t, null, range.t, range.first_expression, range.last_expression, false )
            elseIf (range instanceOf CmdRangeDownTo)
              cmd_forEach = CmdForEachValueInRangeDownTo( t, t, null, range.t, range.first_expression, range.last_expression, true )
            elseIf (range instanceOf CmdRangeDownToGreaterThan)
              cmd_forEach = CmdForEachValueInRangeDownTo( t, t, null, range.t, range.first_expression, range.last_expression, false )
            else
              throw t.error( "TODO: unsupported range in parse_forEach" )
            endIf
          else
            throw t.error( "TODO: anonymous forEach in parse_forEach" )
          endIf
        else
          throw t.error( "TODO: anonymous forEach in parse_forEach" )
        endIf

      elseIf (consume(Token.keyword_in))
        # In forEach (value in collection), extract name of 'value' from previously parsed control_expression
        local access = control_expression as CmdAccess
        if (access is null) throw control_expression.error( "Element name expected." )

        control_expression = parse_expression
        local range = control_expression as CmdRange
        if (range?)
          if (range instanceOf CmdRangeUpTo)
            cmd_forEach = CmdForEachValueInRangeUpTo( t, access.t, access.name, range.t, range.first_expression, 
              range.last_expression, true )
          elseIf (range instanceOf CmdRangeUpToLessThan)
            cmd_forEach = CmdForEachValueInRangeUpTo( t, access.t, access.name, range.t, range.first_expression, 
              range.last_expression, false )
          elseIf (range instanceOf CmdRangeDownTo)
            cmd_forEach = CmdForEachValueInRangeDownTo( t, access.t, access.name, range.t, range.first_expression, 
              range.last_expression, true )
          elseIf (range instanceOf CmdRangeDownToGreaterThan)
            cmd_forEach = CmdForEachValueInRangeDownTo( t, access.t, access.name, range.t, range.first_expression, 
            range.last_expression, false )
          else
            throw range.t.error( "TODO: parse forEach-in with type " + range.type_name )
          endIf
        else
          cmd_forEach = CmdForEachElementInCollection( t, access.t, access.name, control_expression )
        endIf
        if (has_parens) must_consume( Token.symbol_close_paren )

      elseIf (consume(Token.keyword_of))
        # In forEach (i of collection), extract name of 'i' from previously parsed control_expression
        local access = control_expression as CmdAccess
        if (access is null) throw control_expression.error( "Element name expected." )

        cmd_forEach = CmdForEachIndexOfCollection( t, access.t, access.name, parse_expression )
        if (has_parens) must_consume( Token.symbol_close_paren )

      else
        throw t.error( "Syntax error parsing forEach." )

      endIf

      if (consume_eols)
        # multi-line while
        parse_multi_line_statements( cmd_forEach.body )
        must_consume( Token.keyword_endForEach )
      else
        # single-line while
        parse_single_line_statements( cmd_forEach.body )
        consume_eols
      endIf

      return cmd_forEach

    method parse_loop->CmdLoop
      local t = read
      local cmd_loop = CmdLoop( t )

      if (not next_is_end_command)
        cmd_loop.count_expression = parse_expression
      endIf

      if(consume_eols)
        parse_multi_line_statements( cmd_loop.body )
        must_consume( Token.keyword_endLoop )
      else
        parse_single_line_statements( cmd_loop.body )
        consume_eols
      endIf

      return cmd_loop

    method parse_try->CmdTry
      local t = read
      local cmd_try = CmdTry( t )

      must_consume_eol
      parse_multi_line_statements( cmd_try.body )

      t = peek
      while (consume(Token.keyword_catch))
        local cur_catch = CmdCatch( t, cmd_try )
        must_consume( Token.symbol_open_paren )

        cur_catch.local_name = read_identifier
        must_consume( Token.symbol_colon )
        cur_catch.local_type = parse_type

        must_consume( Token.symbol_close_paren )
        must_consume_eol

        parse_multi_line_statements( cur_catch.body )
        cmd_try.catches.add( cur_catch )
      endWhile

      must_consume( Token.keyword_endTry )

      return cmd_try

    method parse_local_declaration( statements:CmdStatementList )
      local_declarations.clear
      local t = read   # "local"

      local first = true
      while (first or consume(Token.symbol_comma))
        first = false
        t = peek
        local name = read_identifier
        local v = Local( t, name )
        if (consume(Token.symbol_equals))
          v.initial_value = parse_expression
        endIf
        local_declarations.add( v )
        this_method.add_local( v )
      endWhile

      if (consume(Token.symbol_colon))
        local type = parse_type
        forEach (v in local_declarations) v.type = type
      else
        forEach (v in local_declarations)
          if (v.type is null and v.initial_value?)
            v.type = v.initial_value.implicit_type
          endIf
        endForEach
      endIf

      forEach (v in local_declarations)
        statements.add( CmdLocalDeclaration(v.t, v) )
        if (v.initial_value?)
          statements.add( CmdWriteLocal(v.t,v,v.initial_value) )
        else
          statements.add( CmdWriteLocalDefault(v.t,v) )
        endIf
      endForEach

    method parse_expression->Cmd
      # if(peek == Token.symbol_equals) println(t)
      consume_eols
      return parse_range

    method parse_range->Cmd
      return parse_range( parse_logical_xor )

    method parse_range( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_upTo))
        return CmdRangeUpTo( t, lhs, parse_logical_xor )
      elseIf (consume(Token.symbol_upToLessThan))
        return CmdRangeUpToLessThan( t, lhs, parse_logical_xor )
      elseIf (consume(Token.symbol_downToGreaterThan))
        return CmdRangeDownToGreaterThan( t, lhs, parse_logical_xor )
      elseIf (consume(Token.keyword_downTo))
        return CmdRangeDownTo( t, lhs, parse_logical_xor )
      else
        return lhs
      endIf

    method parse_logical_xor->Cmd
      return parse_logical_xor( parse_logical_or )

    method parse_logical_xor( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.keyword_xor))
        consume_eols
        return parse_logical_xor( CmdLogicalXor(t, lhs, parse_logical_or) )
      endIf
      return lhs

    method parse_logical_or->Cmd
      return parse_logical_or( parse_logical_and )

    method parse_logical_or( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.keyword_or))
        consume_eols
        return parse_logical_or( CmdLogicalOr(t, lhs, parse_logical_and) )
      endIf
      return lhs

    method parse_logical_and->Cmd
      return parse_logical_and( parse_comparison )

    method parse_logical_and( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.keyword_and))
        consume_eols
        return parse_logical_and( CmdLogicalAnd(t, lhs, parse_comparison) )
      endIf
      return lhs

    method parse_comparison->Cmd
      return parse_comparison( parse_bitwise_xor )

    method parse_comparison( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_eq))
        consume_eols
        return parse_comparison( CmdCompareEQ(t, lhs, parse_bitwise_xor) )
      elseIf (consume(Token.keyword_is))
        consume_eols
        return parse_comparison( CmdCompareIs(t, lhs, parse_bitwise_xor) )
      elseIf (consume(Token.symbol_ne))
        consume_eols
        return parse_comparison( CmdCompareNE(t, lhs, parse_bitwise_xor) )
      elseIf (consume(Token.keyword_isNot))
        consume_eols
        return parse_comparison( CmdCompareIsNot(t, lhs, parse_bitwise_xor) )
      elseIf (consume(Token.symbol_lt))
        consume_eols
        return parse_comparison( CmdCompareLT(t, lhs, parse_bitwise_xor) )
      elseIf (consume(Token.symbol_gt))
        consume_eols
        return parse_comparison( CmdCompareGT(t, lhs, parse_bitwise_xor) )
      elseIf (consume(Token.symbol_le))
        consume_eols
        return parse_comparison( CmdCompareLE(t, lhs, parse_bitwise_xor) )
      elseIf (consume(Token.symbol_ge))
        consume_eols
        return parse_comparison( CmdCompareGE(t, lhs, parse_bitwise_xor) )
      elseIf (consume(Token.keyword_instanceOf))
        consume_eols
        return CmdInstanceOf( t, lhs, parse_type )
      elseIf (consume(Token.keyword_notInstanceOf))
        consume_eols
        return CmdLogicalNot( t, CmdInstanceOf( t, lhs, parse_type ) )
      endIf
      return lhs

    method parse_bitwise_xor->Cmd
      return parse_bitwise_xor( parse_bitwise_or )

    method parse_bitwise_xor( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_bitwise_xor))
        consume_eols
        return parse_bitwise_xor( CmdBitwiseXor(t,lhs,parse_bitwise_or) )
      endIf
      return lhs

    method parse_bitwise_or->Cmd
      return parse_bitwise_or( parse_bitwise_and )

    method parse_bitwise_or( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_bitwise_or))
        consume_eols
        return parse_bitwise_or( CmdBitwiseOr(t,lhs,parse_bitwise_and) )
      endIf
      return lhs

    method parse_bitwise_and->Cmd
      return parse_bitwise_and( parse_bitwise_shift )

    method parse_bitwise_and( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_ampersand))
        consume_eols
        return parse_bitwise_and( CmdBitwiseAnd(t,lhs,parse_bitwise_shift) )
      endIf
      return lhs

    method parse_bitwise_shift->Cmd
      return parse_bitwise_shift( parse_add_subtract )

    method parse_bitwise_shift( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_shl))
        consume_eols
        return parse_add_subtract( CmdBitwiseSHL(t,lhs,parse_add_subtract) )
      elseIf (consume(Token.symbol_shr))
        consume_eols
        return parse_add_subtract( CmdBitwiseSHR(t,lhs,parse_add_subtract) )
      elseIf (consume(Token.symbol_shrx))
        consume_eols
        return parse_add_subtract( CmdBitwiseSHRX(t,lhs,parse_add_subtract) )
      endIf
      return lhs

    method parse_add_subtract->Cmd
      return parse_add_subtract( parse_multiply_divide_mod )

    method parse_add_subtract( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_plus))
        consume_eols
        return parse_add_subtract( CmdAdd(t,lhs,parse_multiply_divide_mod) )
      elseIf (consume(Token.symbol_minus))
        consume_eols
        return parse_add_subtract( CmdSubtract(t,lhs,parse_multiply_divide_mod) )
      endIf
      return lhs

    method parse_multiply_divide_mod->Cmd
      return parse_multiply_divide_mod( parse_power )

    method parse_multiply_divide_mod( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_times))
        consume_eols
        return parse_multiply_divide_mod( CmdMultiply(t,lhs,parse_power) )
      elseIf (consume(Token.symbol_divide))
        consume_eols
        return parse_multiply_divide_mod( CmdDivide(t,lhs,parse_power) )
      elseIf (consume(Token.symbol_percent))
        consume_eols
        return parse_multiply_divide_mod( CmdMod(t,lhs,parse_power) )
      endIf
      return lhs

    method parse_power->Cmd
      return parse_power( parse_pre_unary )

    method parse_power( lhs:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_power))
        consume_eols
        return parse_power( CmdPower(t,lhs,parse_pre_unary) )
      endIf
      return lhs

    method parse_pre_unary->Cmd
      local t = peek
      if (consume(Token.keyword_not))
        consume_eols
        return CmdLogicalNot( t, parse_pre_unary )
      elseIf (consume(Token.symbol_minus))
        consume_eols
        return CmdNegate( t, parse_pre_unary )
      elseIf (consume(Token.symbol_bitwise_not))
        consume_eols
        return CmdBitwiseNot( t, parse_pre_unary )
      endIf
      return parse_post_unary

    method parse_post_unary->Cmd
      return parse_post_unary( parse_delegate_access )

    method parse_post_unary( operand:Cmd )->Cmd
      local t = peek
      if (consume(Token.symbol_question_mark))
        return parse_post_unary( CmdLogicalize(t,operand) )
      endIf
      return operand


    method parse_delegate_access->Cmd
      return parse_delegate_access( parse_access )

    method parse_delegate_access( lhs:Cmd )->Cmd
      local t = peek
      if(consume(Token.symbol_scope))
        local cmd_delegate : CmdDelegate

        local delegate_method_name = peek->String
        must_consume( Token.identifier )

        if (not next_is(Token.symbol_open_paren)) return CmdUnqualifiedDelegateSelector( t, lhs, delegate_method_name )

        local buffer        = StringBuilder()
        local sig_buffer    = StringBuilder()
        local param_types = Type[]
        local ret_type : Type

        sig_buffer.print( delegate_method_name )
        if (consume( Token.symbol_open_paren ))
          sig_buffer.print( "(" )
          if (consume( Token.symbol_close_paren ))
            sig_buffer.print( ")" )
          else
            param_types.add( parse_type )
            buffer.print( param_types.last->String )
            sig_buffer.print( param_types.last->String )

            while (consume( Token.symbol_comma ))
              buffer.print( "_" )
              sig_buffer.print(",")
              param_types.add( parse_type )
              buffer.print( param_types.last->String )
              sig_buffer.print( param_types.last->String )
            endWhile
            must_consume( Token.symbol_close_paren )
            sig_buffer.print( ")" )

          endIf
        else
          sig_buffer.print("()")
        endIf

        if (consume( Token.symbol_arrow ))
          ret_type = parse_type
          buffer.print( "__" + ret_type.name )
          sig_buffer.print( "->" + ret_type.name )
        endIf

        local base_class_name = "Delegate__"
        if (buffer.count?) base_class_name += buffer->String

        # if (not ret_type?) base_class_name += "NORETURN"
        local extended_class_name = "Delegate__" + lhs.type + "__" + ...
                                           delegate_method_name + ...
                                           "__" + buffer->String

        cmd_delegate = CmdDelegate( t, lhs, delegate_method_name, ...
                                    sig_buffer->String, base_class_name, ...
                                    extended_class_name, param_types, ret_type )
        return cmd_delegate

      endIf

      return lhs


    method parse_access->Cmd
      return parse_access( parse_term )

    method parse_access( operand:Cmd )->Cmd
      local t = peek

      if (consume(Token.symbol_period))
        # Part access e.g. obj.value or an inline keyword operator, e.g. obj.as.Type
        local t2 = peek
        if (consume_token_and_period(Token.keyword_as))            consume_eols; return parse_access( CmdRecastAsType(t2,operand,parse_type) );
        if (consume_token_and_period(Token.keyword_instanceOf))    consume_eols; return parse_access( CmdInstanceOf(t2,operand,parse_type) );
        if (consume_token_and_period(Token.keyword_is))            consume_eols; return parse_access( CmdCompareIs(t2,operand,parse_term) );
        if (consume_token_and_period(Token.keyword_isNot))         consume_eols; return parse_access( CmdCompareIsNot(t2,operand,parse_term) );
        if (consume_token_and_period(Token.keyword_not))           consume_eols; return parse_access( CmdLogicalNot(t2,operand) );
        if (consume_token_and_period(Token.keyword_notInstanceOf)) consume_eols; return parse_access( CmdLogicalNot(t2,CmdInstanceOf(t2,operand,parse_type)) );

        local access = parse_access_command( t )
        access.operand = operand
        return parse_access( access )

      elseIf (consume(Token.symbol_open_bracket))
        # Parse obj[index]
        consume_eols
        local access = CmdElementAccess( t, operand )
        local first = true
        while (first or consume(Token.symbol_comma))
          first = false
          access.args.add( parse_expression )
          consume_eols
        endWhile
        consume_eols
        must_consume( Token.symbol_close_bracket )
        return parse_access( access )

      elseIf (consume(Token.symbol_arrow))
        # Conversion operation e.g. value->Integer
        consume_eols
        local to_type = parse_type
        local args = parse_args

        if (args?)
          # operand->Type(args) -> operand.to(args)->Type
          return parse_access( CmdConvertToType( t, CmdAccess(t,operand,"to_"+to_type,args), to_type ) )
        endIf

        return parse_access( CmdConvertToType(t,operand,to_type) )

      elseIf (consume(Token.keyword_as))
        # Recast operation e.g. 65 as Character
        consume_eols
        local as_type = parse_type
        return parse_access( CmdRecastAsType(t,operand,as_type) )

      endIf

      return operand

    method parse_access_command( t:Token )->CmdAccess
      consume_eols

      local direct_access = consume( Token.symbol_at )

      local name = read_identifier
      name = parse_delegate_or_task_type_name( t, name )
      if (next_is(Token.symbol_open_specialize)) name += parse_specialization_string

      while (consume(Token.symbol_empty_brackets)) name += "[]"

      if (direct_access) name = "@" + name

      local access = CmdAccess( t, name )
      access.args = parse_args
      return access

    # TODO: Add multi-line handling
    method parse_args->CmdArgs
      if (not consume(Token.symbol_open_paren)) return null
      consume_eols

      local args = CmdArgs()
      if (not consume(Token.symbol_close_paren))
        local first = true
        while (first or consume(Token.symbol_comma))
          consume_eols
          first = false
          args.add( parse_expression )
        endWhile
        consume_eols
        must_consume( Token.symbol_close_paren )
      endIf

      return args

    method parse_specialization_string->String
      if (not next_is(Token.symbol_open_specialize)) return ""

      string_buffer.clear
      consume( Token.symbol_open_specialize )
      string_buffer.print( "<<" )
      local nesting_level = 1
      while (reader.has_another)
        if (next_is(Token.eol))
          throw peek.error( "Closing '>>' expected before end of line." )
        elseIf (consume(Token.symbol_open_specialize))
          string_buffer.print("<<")
          ++nesting_level
        elseIf (consume(Token.symbol_close_specialize))
          --nesting_level
          if (nesting_level == 0)
            escapeWhile
          else
            string_buffer.print( ">>" )
          endIf
        else
          string_buffer.print( read->String )
        endIf
      endWhile
      string_buffer.print( ">>" )

      return string_buffer->String

    method parse_term->Cmd
      local t = peek
      if (consume(Token.symbol_open_paren))
        consume_eols
        local result = parse_expression
        consume_eols
        must_consume( Token.symbol_close_paren )
        return result

      elseIf (next_is(Token.identifier) or next_is(Token.symbol_at))
        return parse_access_command( t )

      elseIf (consume(Token.literal_String))
        if (consume(Token.symbol_open_paren))
          local first = true
          local args = CmdArgs()
          while (first or consume(Token.symbol_comma))
            first = false
            args.add( parse_expression )
          endWhile
          must_consume( Token.symbol_close_paren )
          return CmdFormattedString( t, t->String, args )
        endIf
        return CmdLiteralString( t, t->String )

      elseIf (consume(Token.keyword_null))
        return CmdLiteralNull(t)
      elseIf (consume(Token.literal_Real))
        return CmdLiteralReal( t, t->Real )
      elseIf (consume(Token.literal_Integer))
        local value = t->Integer
        return CmdLiteralInteger( t, value )
      elseIf (consume(Token.literal_Character))
        local value = t->Character
        return CmdLiteralCharacter( t, value->Character )
      elseIf (consume(Token.literal_Logical_true))
        return CmdLiteralLogical( t, true )
      elseIf (consume(Token.literal_Logical_false))
        return CmdLiteralLogical( t, false )
      elseIf (consume(Token.keyword_this))
        return CmdThis( t, this_type )
      elseIf (consume(Token.keyword_function))
        return parse_function( t )
      elseIf (consume(Token.keyword_pi))
        return CmdLiteralReal( t, pi )

      elseIf (consume(Token.symbol_open_bracket))
        # [ literal, list ]
        if (parsing_properties?)
          local cmd = CmdNewObject( t, Types.reference(t,"PropertyList") ) : Cmd

          local first = true
          while (first or consume(Token.symbol_comma))
            first = false
            local value = parse_expression
            cmd = CmdAccess( value.t, cmd, "add", CmdArgs(value) )
            consume_eols
          endWhile
          must_consume( Token.symbol_close_bracket )

          return cmd

        else
          local list = CmdLiteralList(t)
          consume_eols
          if (not consume(Token.symbol_close_bracket))
            local first = true
            while (first or consume(Token.symbol_comma))
              first = false
              list.args.add( parse_expression )
              consume_eols
            endWhile
            must_consume( Token.symbol_close_bracket )
          endIf
          return list
        endIf

      elseIf (consume(Token.symbol_open_brace))
        # { key:value, key:value, ... }
        local table = CmdLiteralTable(t)
        consume_eols
        if (not consume(Token.symbol_close_brace))
          local first = true
          while (first or consume(Token.symbol_comma))
            first = false
            if (peek.type == Token.identifier)
              local kt = read
              table.keys.add( CmdLiteralTableKey(kt, kt->String) )
            else
              ++parsing_properties
              table.keys.add( parse_expression )
              --parsing_properties
            endIf
            must_consume( Token.symbol_colon )
#local expr = parse_expression
#trace expr
#table.values.add( expr )
            ++parsing_properties
            table.values.add( parse_expression )
            --parsing_properties
            consume_eols
          endWhile
          must_consume( Token.symbol_close_brace )
        endIf
        return table

      elseIf (consume(Token.symbol_empty_braces))
        return CmdNewObject( t, Types.reference( t, "PropertyTable" ) )

      elseIf (consume(Token.symbol_empty_brackets))
        return CmdNewObject( t, Types.reference( t, "PropertyList" ) )

      elseIf (consume(Token.keyword_prior))
        consume_eols
        must_consume( Token.symbol_period )
        consume_eols
        local name = read_identifier
        local args = parse_args
        return CmdPriorCall( t, name, args )

      elseIf (next_is(Token.keyword_delegate))
        return parse_delegate

      elseIf (consume(Token.alias_arg_index))
        return alias_args[ t->Integer ].clone

      else
        #throw peek.error( "Syntax error: unexpected '$'." (peek) )
        throw peek.error( "Syntax error: unexpected '" + peek + "' (" + peek.type + ")." )
      endIf

    method parse_function( t:Token )->Cmd
      local fn_cmd = CmdFunction( t )

      if (consume(Token.symbol_open_paren))
        # parameter names
        consume_eols
        if (next_is(Token.identifier))
          fn_cmd.parameter_names.add( read_identifier )
          while (consume(Token.symbol_comma))
            consume_eols
            fn_cmd.parameter_names.add( read_identifier )
          endWhile
        endIf
        consume_eols
        must_consume( Token.symbol_close_paren )
      endIf

      if (consume_eols)
        # multi-line
        parse_multi_line_statements( fn_cmd.body )
        must_consume( Token.keyword_endFunction )

      else
        # implicit-result-expression
        must_consume( Token.symbol_fat_arrow )

        consume( Token.keyword_return )
        local expr = parse_expression
        fn_cmd.body.add( CmdReturnValue(expr.t,expr) )
      endIf

      return fn_cmd

endClass

