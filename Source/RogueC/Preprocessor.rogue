class Preprocessor
  GLOBAL PROPERTIES
    definitions = Definitions()

  GLOBAL METHODS
    method define( name:String, definition:String )
      define( name, Tokenizer().tokenize("[Command Line]",definition) )

    method define( name:String, tokens:Token[] )
      define( Define(name,tokens) )

    method define( def:Define )
      definitions.add( def )

    method define( name:String, value:Logical )
      local t  = Token( ?:{ value: TokenType.keyword_true || TokenType.keyword_false } )
      t.filepath = "compiler-generated"
      define( name, [t] )

    method logicalize( term: Value, loose = false: Logical )->Logical
      if (not loose)
        if (term == false) return false
        if (term == 0) return false
        if (term.is_null) return false
        if (term == "") return false
        return true
      endIf
      if (term.is_number)
        return term != 0
      endIf
      local v = term->String.to_lowercase
      return not (v == "" or v == "0" or v == "false" or v == "null" or v == "no")

    method valueize( tok: Token )->Value
      which (tok.type)
        case TokenType.keyword_true
          return true
        case TokenType.keyword_false
          return false
        case TokenType.literal_int32
          return tok->Int32
        case TokenType.literal_int64
          return tok->Int64
        case TokenType.literal_real64
          return tok->Real64
        case TokenType.keyword_false
          return false
        case TokenType.keyword_true
          return true
        case TokenType.keyword_null
          return null
        case TokenType.literal_character,TokenType.literal_string
          return tok->String
      endWhich
      return null

    method valueize( toks: Token[] )->Value
      if (toks.count == 2 and toks[0].type == TokenType.symbol_minus)
        local v = valueize(toks[1])
        if (v.is_number)
          return v * -1
        endIf
        return " ".join(toks.mapped<<String>>( (x)=>x ))
      elseIf (toks.count == 0)
        # Count "$define FOO" as true
        return true
      elseIf (toks.count != 1)
        # Just string it all out.
        return " ".join(toks.mapped<<String>>( (x)=>x ))
      endIf
      local r = valueize(toks[0])
      if (r is null)
        return toks[0]->String
      endIf
      return r

  PROPERTIES
    parser : Parser  # the parser that will be parsing these tokens later
    reader : PreprocessorTokenReader
    tokens : Token[]

    cur_module        : String
    cur_module_prefix : String
    metablock_stack = Token[]

  METHODS
    method init( parser )

    method process( tokens )->Token[]
      reader = PreprocessorTokenReader( tokens )
      tokens = Token[]( (tokens.count * 1.1)->Int32 )
      process( true, 0, false )

      return tokens

    # -------------------------------------------------------------------------

    method consume( type:TokenType )->Logical
      if (reader.peek.type is not type) return false
      reader.read
      return true

    method consume( identifier:String )->Logical
      local t = reader.peek
      if (t.type is not TokenType.identifier) return false
      if (t->String != identifier) return false
      reader.read
      return true

    method process( keep_tokens:Logical, depth:Int32, stop_on_eol:Logical )
      ++depth
      local repeat_string_concatenation = false
      while (reader.has_another)
        local t = reader.read

        local t_type = t.type
        if (t.is_directive)
          if (t_type is TokenType.meta_define)
            read_define( keep_tokens, definitions )
            nextIteration

          elseIf (t_type is TokenType.meta_macro)
            read_macro( keep_tokens, definitions )
            nextIteration

          elseIf (t_type is TokenType.meta_defined)
            local defined_word = t->String
            if (keep_tokens)
              if (find_definition(defined_word)?)
                tokens.add( Token(TokenType.keyword_true).set_location(t) )
              else
                tokens.add( Token(TokenType.keyword_false).set_location(t) )
              endIf
            endIf
            nextIteration

          elseIf (t_type is TokenType.meta_error)
            local message_t = reader.read
            if (message_t.type is not TokenType.literal_string)
              throw t.error( "Literal string error message expected." )
            endIf
            if (keep_tokens)
              throw message_t.error( message_t->String )
            endIf
            nextIteration

          elseIf (t_type is TokenType.meta_include)
            local filepath_t = reader.read
            if (filepath_t.type is not TokenType.literal_string)
              throw reader.error( "Filepath expected." )
            endIf
            local attributes = parse_include_attributes
            if (keep_tokens)
              RogueC.set_include_attributes( filepath_t, filepath_t->String, attributes )
              RogueC.include_source( t, filepath_t->String, &is_optional=attributes.is_optional )
            endIf
            nextIteration

          elseIf (t_type is TokenType.meta_elseIf)
            if (depth == 1) throw t.error( "Syntax error - $elseIf does not match any previous $if." )
            reader.push( t )
            return

          elseIf (t_type is TokenType.meta_else)
            if (depth == 1) throw t.error( "Syntax error - $else does not match any previous $if." )
            reader.push( t )
            return

          elseIf (t_type is TokenType.meta_endIf)
            if (depth == 1) throw t.error( "Syntax error - $endIf does not match any previous $if." )
            reader.push( t )
            return

          elseIf (t_type is TokenType.meta_if)
            local found_true = parse_logical_expression
            local single_line = not reader.next_is( TokenType.eol )

            if (found_true)
              process( keep_tokens, depth, single_line )
            else
              process( false, depth, single_line )
            endIf

            while (reader.peek.type is TokenType.meta_elseIf)
              reader.read
              local value = parse_logical_expression

              if (found_true)
                process( false, depth, single_line )
              else
                found_true = value
                if (value) process( keep_tokens, depth, single_line )
                else       process( false, depth, single_line )
              endIf
            endWhile

            if (reader.peek.type is TokenType.meta_else)
              reader.read
              if (found_true) process( false,       depth, single_line )
              else            process( keep_tokens, depth, single_line )
            endIf

            if (not single_line) must_consume( TokenType.meta_endIf )
            nextIteration

          elseIf (t_type is TokenType.meta_warning)
            local message_t = reader.read
            if (message_t.type is not TokenType.literal_string)
              throw t.error( "Literal string warning message expected." )
            endIf
            if (keep_tokens)
              Console.error.println message_t.warning( message_t->String )
            endIf
            nextIteration

          elseIf (t_type is TokenType.meta_module)
            if (reader.peek.type is TokenType.identifier)
              if (reader.peek(1).type is TokenType.symbol_open_specialize)
                # Module Template: module M<<Args>>
                # Read until EOI or next 'module', either discarding or storing in ModuleTemplate
                reader.push_unfiltered
                if (keep_tokens)
                  local name_t = reader.peek
                  local base_name = reader.read_identifier
                  local placeholders = Token[]
                  reader.read  # <<
                  local first = true
                  while (first or consume(TokenType.symbol_comma))
                    if (first) first = false
                    if (not reader.peek.type is TokenType.placeholder_id) throw reader.peek.error( "$PlaceholderID expected." )
                    placeholders.add( reader.read )
                  endWhile
                  must_consume( TokenType.symbol_close_specialize )
                  local template_name = "$<<$>>" (base_name,placeholders.count)
                  local module_template = Program.module_templates[ template_name ]
                  if (not module_template)
                    ensure module_template
                    Program.module_templates[ template_name ] = module_template
                  endIf

                  local section = ModuleTemplateSection( t, name_t, placeholders )
                  module_template.sections.add( section )

                  while (reader.has_another and reader.peek.type is not TokenType.meta_module)
                    section.tokens.add( reader.read )
                  endWhile

                else
                  while (reader.has_another and reader.peek is not TokenType.meta_module) reader.read
                endIf
                reader.pop_unfiltered
                nextIteration

              else
                # Build collection of non-template module names so that template instantiation can auto-generate
                # names that don't conflict.
                Program.module_names.add( reader.peek->String )
              endIf
            endIf

            if (keep_tokens) tokens.add( t )

            if (next_is(TokenType.identifier))
              if (keep_tokens)
                tokens.add( reader.peek )
                cur_module = reader.read_identifier
                cur_module_prefix = cur_module + "::"
              else
                reader.read
              endIf
            else
              consume( TokenType.symbol_colon_colon )
              if (keep_tokens) cur_module = null; cur_module_prefix = null
            endIf

            if (next_is(TokenType.symbol_open_bracket))
              # [api essential]
              local next_token = reader.read
              if (keep_tokens) tokens.add( next_token )
              while (reader.has_another)
                next_token = reader.read
                if (keep_tokens) tokens.add( next_token )
                if (next_token.type is TokenType.symbol_close_bracket) escapeWhile
              endWhile
            endIf

            nextIteration

          elseIf (t_type is TokenType.meta_uses)
            # Only check for module templates here in order to instantiate them; 'uses' with standard modules can wait until later
            if (not keep_tokens)
              while (reader.has_another and not reader.next_is(TokenType.eol)) reader.read

            elseIf (reader.peek.type is TokenType.identifier and reader.peek(1).type is TokenType.symbol_open_specialize)
              local name_t = reader.peek
              local base_name = reader.read_identifier
              local args = Token[][]
              reader.read  # <<
              use builder=StringBuilder.pool
                builder.print( base_name ).print( "<<" )
                local first = true
                while (first or consume(TokenType.symbol_comma))
                  if (first) first = false
                  else       builder.print( ',' )
                  local tokens = Token[]
                  args.add( tokens )
                  local arg_depth = 0
                  while (reader.has_another)
                    local next_type = reader.peek.type
                    if (arg_depth == 0)
                      if (next_type is TokenType.symbol_comma or next_type is TokenType.symbol_close_specialize) escapeWhile
                    endIf

                    if (next_type is TokenType.symbol_open_paren or next_type is TokenType.symbol_open_bracket or...
                      next_type is TokenType.symbol_open_brace or next_type is TokenType.symbol_open_specialize)
                      ++arg_depth
                    elseIf (next_type is TokenType.symbol_close_paren or next_type is TokenType.symbol_close_bracket or...
                      next_type is TokenType.symbol_close_brace or next_type is TokenType.symbol_close_specialize)
                      --arg_depth
                    endIf

                    local next_t = reader.read
                    builder.print( next_t )
                    tokens.add( next_t )
                  endWhile

                endWhile
                must_consume( TokenType.symbol_close_specialize )
                builder.print( ">>" )

                local instance_name = builder->String
                local template_name = "$<<$>>" (base_name,args.count)

                local as_t = reader.peek
                local as_name : String
                if (consume(TokenType.keyword_as))
                  as_name = reader.read_identifier
                else
                  # put 'uses' 'module-name<<...>>' back in the token stream for later
                  tokens.add( t )
                  tokens.add( TokenType.identifier.create_token(name_t,instance_name) )
                endIf

                local instance = Program.module_instance_lookup[ instance_name ]
                if (instance)
                  if (instance.as_name is null)
                    instance.as_name = as_name
                  elseIf (as_name)
                    if (as_name != instance.as_name)
                      throw as_t.error( "Inconsistent uses-as names ($ vs $)." (as_name,instance.as_name) )
                    endIf
                  endIf

                else
                  ensure instance( t, template_name, args, as_name )
                  Program.module_instance_lookup[ instance_name ] = instance
                  Program.module_instance_list.add( instance )
                endIf

                #local instance = ModuleInstance( t, "$<<$>>"(base_name,args.count), args )
                #trace base_name, args
              endUse
              nextIteration

            endIf


          elseIf (t_type is TokenType.meta_block)
            if (keep_tokens)
              metablock_stack.add( t )
              if (reader.local_definitions.count)
                reader.local_definitions.add( reader.local_definitions.last.cloned )
              else
                reader.local_definitions.add( Definitions() )
              endIf
            endIf
            nextIteration

          elseIf (t_type is TokenType.meta_endBlock)
            if (keep_tokens)
              if (metablock_stack.is_empty) throw t.error( "$endBlock without preceding $block" )
              metablock_stack.remove_last
              reader.local_definitions.remove_last
            endIf
            nextIteration

          elseIf (t_type is TokenType.meta_localDefine)
            if (keep_tokens)
              if (reader.local_definitions.is_empty) reader.local_definitions.add( Definitions() )
              read_define( keep_tokens, reader.local_definitions.last )
            else
              read_define( keep_tokens, null )
            endIf
            nextIteration

          elseIf (t_type is TokenType.meta_localMacro)
            if (keep_tokens)
              if (reader.local_definitions.is_empty) reader.local_definitions.add( Definitions() )
              read_macro( keep_tokens, reader.local_definitions.last )
            else
              read_macro( keep_tokens, null )
            endIf
            nextIteration

          elseIf (t_type is TokenType.meta_moduleName)
            if (keep_tokens)
              if (cur_module) tokens.add( TokenType.literal_string.create_token(t,cur_module) )
              else            tokens.add( TokenType.literal_string.create_token(t,"") )
              repeat_string_concatenation = true
            endIf
            nextIteration

          endIf
        endIf

        if (t_type is TokenType.keyword_class or t_type is TokenType.keyword_routine or t_type is TokenType.keyword_enum or ...
            t_type is TokenType.keyword_global)
          # Register this class/enum/routine/global module::id
          if (reader.peek.type is TokenType.identifier)
            if (keep_tokens) tokens.add( t )
            t = reader.read
            if (keep_tokens)
              local unqualified_name = t->String
              local qualified_name = unqualified_name
              if (qualified_name.begins_with("::"))
                # ::x -> x
                qualified_name = unqualified_name.after_first("::")
                if (t_type is TokenType.keyword_global) Program.add_module_global( "", qualified_name )
              elseIf (cur_module)
                # x -> ModuleName::x
                if (not unqualified_name.begins_with(cur_module_prefix))
                  if (t_type is TokenType.keyword_global)
                    Program.add_module_global( cur_module, unqualified_name )
                  else
                    Program.add_module_id( cur_module, unqualified_name )
                  endIf
                  qualified_name = (cur_module_prefix + unqualified_name)
                endIf
              else
                if (t_type is TokenType.keyword_global) Program.add_module_global( "", qualified_name )
              endIf
              if (qualified_name is not unqualified_name) t = t.type.create_token(t,qualified_name)
              tokens.add( t )
            endIf
            nextIteration
          endIf
        endIf

        if (t.type is TokenType.literal_string)
          while (reader.peek.type is TokenType.literal_string)
            t = t.type.create_token( t, t->String + reader.read->String )
          endWhile
        endIf

        if (keep_tokens) tokens.add( t )
        if (stop_on_eol and t.type is TokenType.eol) escapeWhile

      endWhile

      if (metablock_stack.count)
        throw metablock_stack.last.error( "Unclosed $block; no matching $endBlock found." )
      endIf

      if (repeat_string_concatenation)
        use rewriter = tokens.rewriter
          forEach (t in rewriter)
            if (t.type is TokenType.literal_string)
              while (rewriter.has_another and rewriter.peek.type is TokenType.literal_string)
                t = t.type.create_token( t, t->String + rewriter.read->String )
              endWhile
            endIf
            rewriter.write( t )
          endForEach
        endUse
      endIf

    method read_define( keep_tokens:Logical, definitions:Definitions )
      if (keep_tokens)
        reader.push_unfiltered
        local defined_word = reader.read_identifier
        local defined_tokens = Token[]()
        while (reader.has_another)
          if (reader.peek.type is TokenType.eol) escapeWhile
          defined_tokens.add( reader.read )
        endWhile
        definitions.add( Define(defined_word,defined_tokens) )
        reader.pop_unfiltered
      else
        # Skip this directive due to conditional compilation - discard tokens to EOL
        while (reader.has_another)
          if (reader.peek.type is TokenType.eol) escapeWhile
          reader.read
        endWhile
      endIf

    method read_macro( keep_tokens:Logical, definitions:Definitions )
      if (keep_tokens)
        reader.push_unfiltered

        local defined_word = reader.read_identifier
        local defined_tokens : Token[]

        contingent
          necessary (consume(TokenType.symbol_open_paren))

          if (reader.peek.type is TokenType.symbol_close_paren)
            reader.read
            necessary (false)
          endIf

          # $macro(a,b) <expression>
          local macro_def = Define( defined_word )
          local first = true
          while (reader.has_another)
            if (first)
              first = false
            else
              if (reader.peek.type is TokenType.symbol_comma) reader.read
              else escapeWhile
            endIf
            local pt = reader.peek
            macro_def.add_parameter_name( pt, reader.read_identifier )
          endWhile
          must_consume( TokenType.symbol_close_paren )

          definitions.add( macro_def )
          defined_tokens = macro_def.tokens

        unsatisfied
          # Store this zero param macro as a regular $define
          ensure defined_tokens
          definitions.add( Define(defined_word,defined_tokens) )

        endContingent

        if (consume(TokenType.eol))
          # Multi-line macro
          while (reader.has_another)
            if (consume(TokenType.meta_endMacro)) escapeWhile
            defined_tokens.add( reader.read )
          endWhile
        elseIf (consume(TokenType.meta_endMacro))
          # Empy macro
        else
          # Single line macro
          while (reader.has_another)
            if (reader.peek.type is TokenType.eol) escapeWhile
            defined_tokens.add( reader.read )
          endWhile
        endIf

        reader.pop_unfiltered

      else
        # Skip this directive due to conditional compilation - discard tokens
        if (consume(TokenType.eol))
          # Multi-line macro
          while (reader.has_another)
            if (consume(TokenType.meta_endMacro)) escapeWhile
            reader.read
          endWhile
        else
          while (reader.has_another)
            if (reader.peek.type is TokenType.eol) escapeWhile
            reader.read
          endWhile
        endIf
      endIf

    method consume_eols
      while (reader.has_another and reader.peek.type is TokenType.eol) reader.read

    method parse_include_attributes->IncludeAttributes
      if (not consume(TokenType.symbol_open_bracket) or consume(TokenType.symbol_close_bracket))
        return IncludeAttributes()
      endIf

      local is_optional = false
      local is_essential = false
      local is_api = false
      consume_eols
      while (reader.has_another and not reader.next_is(TokenType.symbol_close_bracket))
        local t = reader.peek
        local id = read_identifier
        which (id)
          case "optional":  is_optional = true
          case "essential": is_essential = true
          case "api":       is_api = true
          others: throw t.error( "Illegal '$'. Possible attributes are 'optional', 'essential', and 'api'." (id) )
        endWhich
        consume_eols
        consume( TokenType.symbol_comma )
        consume_eols
      endWhile
      must_consume( TokenType.symbol_close_bracket )
      return IncludeAttributes( &=is_optional, &=is_essential, &=is_api )

    method must_consume( type:TokenType )
      local message = "Expected '$'." (type.name)
      if (not reader.has_another) throw RogueError( message )
      local t = reader.read
      if (t.type is not type) throw t.error( message )

    method next_is( type:TokenType )->Logical
      return reader.next_is( type )

    method parse_logical_expression->Logical
      reader.push_unfiltered
      local r = parse_logical_or
      reader.pop_unfiltered
      return r

    method parse_logical_or->Logical
      return parse_logical_or( parse_logical_and )

    method parse_logical_or( lhs:Logical )->Logical
      if (consume(TokenType.keyword_or)) return parse_logical_or( parse_logical_and or lhs )
      return lhs

    method parse_logical_and->Logical
      return parse_logical_and( parse_logical_compare )

    method parse_logical_and( lhs:Logical )->Logical
      if (consume(TokenType.keyword_and)) return parse_logical_and( parse_logical_compare and lhs )
      return lhs

    method parse_logical_compare->Logical
      return parse_logical_compare( parse_logical_term )

    method parse_logical_compare( lhs:Value )->Logical
      # lhs is on the right so that we don't short circuit -- we need to parse everything one
      # way or another!
      if (consume(TokenType.symbol_eq)) return parse_logical_compare( parse_logical_term == lhs )
      if (consume(TokenType.symbol_ne)) return parse_logical_compare( parse_logical_term != lhs )
      if (consume(TokenType.symbol_ge)) return parse_logical_compare( parse_logical_term <= lhs )
      if (consume(TokenType.symbol_gt)) return parse_logical_compare( parse_logical_term <  lhs )
      if (consume(TokenType.symbol_le)) return parse_logical_compare( parse_logical_term >= lhs )
      if (consume(TokenType.symbol_lt)) return parse_logical_compare( parse_logical_term >  lhs )
      return logicalize(lhs)

    method find_definition( name: String )->Define
      local result = find_definition( name, 0 )
      if (result) return result

      # No zero-parameter definitions exist; return tokens for any macro with the right name
      if (reader.local_definitions.count)
        local def = reader.local_definitions.last.find_first( name )
        if (def) return def
      endIf

      local def = definitions.find_first( name )
      if (def) return def
      return null

    method find_definition( name:String, arg_count:Int32 )->Define
      if (arg_count == 0)
        if (reader.local_definitions.count)
          local def = reader.local_definitions.last.find( name, 0 )
          if (def) return def
        endIf
      endIf

      local def = definitions.find( name, 0 )
      if (def) return def
      return null

    method parse_logical_term->Value
      loop
        local t = reader.peek
        if (consume(TokenType.keyword_not))
          local result = (not logicalize(parse_logical_term))
          return result
        endIf

        if (consume(TokenType.symbol_open_paren))
          local result = parse_logical_expression
          must_consume(TokenType.symbol_close_paren)
          return result
        endIf

        if (t.type is TokenType.symbol_minus)
          reader.read
          local v = parse_logical_term
          if (not v.is_number)
            throw t.error( "Syntax error: unexpected '-'." )
          endIf
          return v * -1
        endIf

        if (consume(TokenType.meta_defined))
          must_consume(TokenType.symbol_open_paren)
          local def = reader.peek
          must_consume(TokenType.identifier)
          local result = find_definition(def->String)?
          must_consume(TokenType.symbol_close_paren)
          return result
        endIf

        if (consume(TokenType.identifier))
          if (t->String == "target")
            must_consume(TokenType.symbol_open_paren)
            local target = reader.peek
            must_consume(TokenType.literal_string)
            local result = RogueC.compile_targets[target->String]->Logical
            must_consume(TokenType.symbol_close_paren)
            return result
          endIf

          local maybe = false
          if (t->String == "optional")
            must_consume(TokenType.symbol_open_paren)
            maybe = true
            t = reader.peek
            must_consume(TokenType.identifier)
          endIf

          local name = t->String
          local v = false : Value
          local def = find_definition(name)
          local has_value = def?
          if (has_value) v = valueize(def.tokens)
          if (v is null) throw reader.peek.error( "Definition '$' does not have a legal value for preprocessor expressions." (name) )

          if (reader.peek->String == "?")
            reader.read
            v = logicalize(v, &loose=true)
          endIf

          if (has_value == false and maybe == false)
            throw t.error( "Unknown preprocessor definition: '$'." (name) )
          endIf

          if (maybe) must_consume(TokenType.symbol_close_paren)

          return v
        endIf

        local v = valueize(t)
        if (v is null) throw reader.peek.error( "Syntax error in directive: '$'." (reader.peek) )
        reader.read
        return v
      endLoop

    method read_identifier->String
      local t = reader.peek
      if (t.type is not TokenType.identifier) throw t.error( "Identifier expected instead of '$'." (t) )
      return reader.read->String

    method reprocess( tokens )->Token[]
      # All the heavy lifting has been done.  Just join any string literals that may now be
      # adjacent after a new template instance.
      use rewriter = tokens.rewriter
        while (rewriter.has_another)
          local t = rewriter.read
          while (t.type is TokenType.literal_string and rewriter.has_another and rewriter.peek.type is TokenType.literal_string)
            t = t.type.create_token( t, t->String + rewriter.read->String )
          endWhile
          rewriter.write( t )
        endWhile
      endUse

      return tokens
endClass


class Definitions
  PROPERTIES
    defines_for_name = StringTable<<DefinesForName>>()

  METHODS
    method add( def:Define )
      local defs = defines_for_name[ def.name ]
      if (not defs)
        defs = DefinesForName( def.name )
        defines_for_name[ def.name ] = defs
      endIf

      block
        forEach (existing_def at index in defs.defines)
          if (existing_def.parameter_count == def.parameter_count)
            def.previous = existing_def
            defs.defines[ index ] = def
            escapeBlock
          endIf
        endForEach
        defs.add( def )
      endBlock

    method cloned->Definitions
      local result = Definitions()
      forEach (def in defines_for_name)
        result.defines_for_name.set( def.name, def.cloned )
      endForEach
      return result

    method contains( name:String )->Logical
      return find_first(name)?

    method find_first( name:String )->Define
      local defs = defines_for_name[ name ]
      if (not defs) return null
      return defs.defines.first

    method find( name:String, param_count:Int32 )->Define
      local defs = defines_for_name[ name ]
      if (not defs) return null

      forEach (def in defs.defines)
        if (def.parameter_count == param_count) return def
      endForEach

      return null

endClass


class DefinesForName
  PROPERTIES
    name    : String
    defines : Define[]

  METHODS
    method init( name, defines=Define[](1) )

    method cloned->DefinesForName
      return DefinesForName( name, defines.cloned )

    method add( def:Define )
      local param_count = def.parameter_count
      forEach (existing at index in defines)
        if (existing.parameter_count == param_count)
          defines.remove_at( index )
          escapeForEach
        endIf
      endForEach
      defines.add( def )

    method count->Int32 [macro]
      this.defines.count

    method definition_for_arg_count( n:Int32 )->Define
      forEach (def in defines)
        if (def.parameter_count == n) return def
      endForEach
      return null

    method find( param_count:Int32 )->Define
      forEach (def in defines)
        if (def.parameter_count == param_count) return def
      endForEach
      return null

    method first->Define [macro]
      this.defines[ 0 ]

    method get( index:Int32 )->Define [macro]
      this.defines[ index ]

    method last->Define [macro]
      this.defines.last

    method tokens_for_arg_count( n:Int32 )->Token[]
      forEach (def in defines)
        if (def.parameter_count == n) return def.tokens
      endForEach
      return null
endClass

class Define
  PROPERTIES
    name            : String
    parameter_count : Int32
    parameter_names : String[]
    tokens          : Token[]
    is_in_use       : Logical   # to prevent recursive expansion
    previous        : Define    # for stacking local definitions

  METHODS
    method init( name, tokens=Token[] )

    method add_parameter_name( t:Token, param_name:String )
      ensure parameter_names( 2 )
      forEach (existing_name in parameter_names)
        if (existing_name == param_name) throw t.error( "Duplicate macro parameter name '$'." (param_name) )
      endForEach
      parameter_names.add( param_name )
      ++parameter_count

    method to->String
      if (parameter_count == 0) return name

      use builder = StringBuilder.pool
        builder.print( name )
        builder.print( '(' )
        forEach (param_name at index in parameter_names)
          if (index > 0) builder.print(',')
          builder.print( param_name )
        endForEach
        builder.print( ')' )
        return builder->String
      endUse
endClass

class IncludeAttributes( &is_optional, &is_essential, &is_api ) [compound];
